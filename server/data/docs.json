[{"pageContent":"Institute Name : Chitkara University (Rajpura , Punjab) \nTeam Name: TechTrek Learners  \nMentor Name: Dr. Rajneesh Talwar (DEAN DICE) \nTeam Members:  \nVishesh (2410992916) \nDishu Singla (2410991043) \nHarmanpreet Singh (2410992751) \nDixit Garg (2410991792) \n \nAI-POWERED SMART FAULT DETECTION SYSTEM for Real-\nTime Industrial Quality Control \nAbstract \nModern  manufacturing  struggles  to  balance  production  speed  with  high-quality  assurance. \nManual  inspections  are  prone  to  fatigue  and  inconsistency,  while  traditional  rule-based \nmachine  vision  fails  under  variations  in  lighting,  angle,  or  defect  type.  Cloud-based  quality \nchecks,  though  powerful,  suffer  from  latency,  high  costs,  and  internet  dependency—making \nthem unsuitable for real-time operations. \nThis Abstract introduces an AI-powered, edge-based inspection system that integrates deep \nlearning  (TensorFlow/PyTorch),  computer  vision  (OpenCV),  explainable  AI  (HeatMap","metadata":{"loc":{"lines":{"from":4,"to":22}}}},{"pageContent":"This Abstract introduces an AI-powered, edge-based inspection system that integrates deep \nlearning  (TensorFlow/PyTorch),  computer  vision  (OpenCV),  explainable  AI  (HeatMap \nvisualization),  automation  (actuators),  and  analytics  (SQL  dashboards  with  optional \ncloud integration). The system ensures millisecond-level defect detection while remaining \nscalable  and  explainable.  Cloud  services  such  as Microsoft  Azure enhance  the  solution  by \nproviding batch calibration, defect trend analysis, and predictive modelling.","metadata":{"loc":{"lines":{"from":21,"to":26}}}},{"pageContent":"Problem Statement \nMitsubishi’s current Product Defect Detection System uses Sound/load waveforms. This \nCurrent  System detects  only Machine/Process  anomalies,  but  not  visual  defects. Defective \nproducts still pass through conveyor belts, risking quality & losses. There are high chances of \nfalse   positives/negatives. Limited   adaptability of Fault   Detection across   different \nindustries/products being Manufactured by Mitsubishi:  \n1. Manual Inspection – Error-prone, slow, and inconsistent due to human fatigue. \n2. Rule-Based Vision Systems – Rigid algorithms easily fail when conditions change. \n3. Cloud-Only  Inspection – Introduces  latency,  requires  stable  internet,  and  adds \nrecurring costs. \nThese gaps lead to: \n• Missed defects and false positives. \n• Higher rework and scrap rates. \n• Lack of historical traceability for continuous improvement. \nThus, industries need a real-time, automated, explainable, and scalable inspection solution. \n \nProposed Solution","metadata":{"loc":{"lines":{"from":29,"to":45}}}},{"pageContent":"• Lack of historical traceability for continuous improvement. \nThus, industries need a real-time, automated, explainable, and scalable inspection solution. \n \nProposed Solution \nThe Proposed  Defect  Detection system  is  deployed on  the  edge,  directly  connected  to \nproduction lines, ensuring zero-latency inspection. \nKey Features: \n• Deep  Learning  (TensorFlow  &  PyTorch): CNNs  trained  on  defect  and  non-defect \nsamples. \n• Preprocessing (OpenCV): Image cleaning, alignment, and contrast normalization. \n• Explainability (HeatMaps): Grad-CAM overlays highlight defect areas. \n• Automation (Actuators): Pneumatic ejectors or robotic arms sort defective items. \n• Analytics (SQL Dashboard): Logs inspection data for trend analysis and traceability. \n• Cloud  Extension  (Azure): Enables  batch  calibration,  predictive  defect  analysis,  and \nenterprise-wide dashboards. \nThis hybrid edge-cloud model ensures real-time defect detection while unlocking long-term \ninsights.","metadata":{"loc":{"lines":{"from":42,"to":58}}}},{"pageContent":"Technology Stack \n1. Cameras & Image Capture \n• Industrial cameras capture products in sync with conveyors. \n• Controlled lighting ensures consistent imaging. \n2. Preprocessing with OpenCV \n• Noise Removal: Gaussian/median filtering. \n• Contrast Adjustment: Histogram equalization for better visibility. \n• Alignment: Perspective correction for consistent input. \n• ROI Extraction: Crops relevant product areas. \n3. Deep Learning Models (TensorFlow / PyTorch) \n• CNNs automatically learn features such as cracks, dents, or misalignments. \n• Transfer  Learning from  pretrained  models  (ResNet,  EfficientNet)  reduces  training \ncosts. \n• On-Device Inference using ONNX Runtime or TensorRT accelerates performance. \n4. Explainability with HeatMaps \n• Grad-CAM generates overlays showing defective regions. \n• Builds trust among operators by providing visual reasoning for AI decisions. \n5. Actuator Integration","metadata":{"loc":{"lines":{"from":61,"to":78}}}},{"pageContent":"4. Explainability with HeatMaps \n• Grad-CAM generates overlays showing defective regions. \n• Builds trust among operators by providing visual reasoning for AI decisions. \n5. Actuator Integration \n• Air jets, diverter gates, or robotic arms separate defective products in real time. \n• Reduces manual intervention and ensures higher throughput. \n6. SQL Dashboard \n• Stores inspection results, defect categories, timestamps. \n• Provides: \no Defect trends over time. \no Batch rejection analysis. \no Root-cause correlation. \n• Enables managers to perform data-driven quality improvements. \n7. Cloud Integration (Azure Example) \nAlthough inference runs at the edge, cloud services enhance analytics: \n• Azure IoT Edge: Syncs edge-collected data. \n• Azure Blob Storage: Stores raw images for retraining models. \n• Azure Synapse Analytics: Batch processes large defect datasets.","metadata":{"loc":{"lines":{"from":75,"to":92}}}},{"pageContent":"• Azure  Machine  Learning: Builds  predictive  models  (e.g.,  defect  probability  by \nshift/machine settings). \n• Power BI: Provides executive dashboards with predictive defect alerts. \nThis hybrid architecture balances low-latency operations with long-term intelligence. \n \nSystem Workflow \n1. Image Capture: Cameras record products under controlled lighting. \n2. Preprocessing (OpenCV): Removes noise, adjusts brightness, aligns orientation. \n3. Inference (CNN in TensorFlow/PyTorch): Classifies product as healthy/defective. \n4. Explainability (HeatMaps): Highlights defect areas. \n5. Action: Actuators reject defective items; alerts notify operators. \n6. Data Logging (SQL): Stores outcomes and metadata. \n7. Continuous Learning: Cloud retrains CNNs with new data, improving accuracy. \nReference Products \n1. ESP-WROOM-32 View \n2. Features Vision Sensor VS70/ Logitech C270 Webcam. View \n3. Mitsubishi Thermal-diode OTP/ MLX90641 IR Array Thermal Imaging Camera. View","metadata":{"loc":{"lines":{"from":94,"to":110}}}},{"pageContent":"Reference Products \n1. ESP-WROOM-32 View \n2. Features Vision Sensor VS70/ Logitech C270 Webcam. View \n3. Mitsubishi Thermal-diode OTP/ MLX90641 IR Array Thermal Imaging Camera. View \n4. Mitsubishi Gf8w Buzzer/Electronic Buzzer 95 DB. View \n5. Ace 16 Watt LED Focus View \n6. Jumping Wires View \nSustainable Development Goals  \n1. SDG 8 – Decent Work and Economic Growth \n2. SDG 9 – Industry, Innovation, and Infrastructure  \n3. SDG 12: Reduced waste, sustainable production. \n4. SDG 17: Industry-academia partnership for sustainability. \n \n \n Impact & Benefits \n• Real-Time Detection: Millisecond-level inference ensures no production delays. \n• Explainability: HeatMaps provide operator trust and root-cause insights. \n• Automation: Minimizes human involvement, increasing efficiency. \n• Traceability: SQL dashboards track every defect and batch-level statistics. \n• Predictive  Maintenance: Cloud  models  predict  conditions  likely  to  cause  future \ndefects.","metadata":{"loc":{"lines":{"from":107,"to":127}}}},{"pageContent":"• Traceability: SQL dashboards track every defect and batch-level statistics. \n• Predictive  Maintenance: Cloud  models  predict  conditions  likely  to  cause  future \ndefects. \n• Scalability: Works for low-cost prototypes and large factories alike.","metadata":{"loc":{"lines":{"from":125,"to":128}}}},{"pageContent":"Example Use Case \nAn automotive  parts  manufacturer produces  50,000  units  daily.  Edge  AI  flags  2%  as \ndefective.  Logs  are  sent  daily  to Azure  Synapse  Analytics.  Over  time,  patterns  reveal  that \ndefects increase during night shifts due to minor lighting variations. Azure ML suggests auto-\ncalibrating camera exposure, reducing defect rates by 30%. \nThis  demonstrates  how real-time  edge  AI ensures  immediate  defect  removal  while cloud \nanalytics continuously refine processes. \n \nConclusion \nThe  proposed AI-powered  camera  inspection  system delivers  an intelligent,  automated, \nand explainable quality control solution. It integrates: \n• Deep Learning (TensorFlow, PyTorch). \n• Preprocessing (OpenCV). \n• Explainability (HeatMaps). \n• Automation (Actuators). \n• Analytics (SQL + Cloud with Azure). \nBy  combining real-time  edge  inspection with cloud-based  analytics,  manufacturers  gain","metadata":{"loc":{"lines":{"from":131,"to":147}}}},{"pageContent":"• Explainability (HeatMaps). \n• Automation (Actuators). \n• Analytics (SQL + Cloud with Azure). \nBy  combining real-time  edge  inspection with cloud-based  analytics,  manufacturers  gain \nboth instant defect removal and long-term optimization. The solution aligns with Industry \n4.0 standards, reducing waste, minimizing recalls, and ensuring customer safety. \nThis  demonstrates  that AI-driven,  hybrid  edge-cloud  inspection  is  not  only  practical  but \nessential for the future of smart manufacturing.","metadata":{"loc":{"lines":{"from":144,"to":151}}}}]